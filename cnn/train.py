import argparseimport numpy as npimport torchimport torch.optim as optimimport torch.nn as nnimport torchvision.transforms as transformsfrom torch.utils.data import DataLoaderfrom torchvision.datasets import MNISTfrom model import CNN_mnistfrom model_tmp import CNNfrom linear_model import Linear_mnist# argsparser = argparse.ArgumentParser(description='which model you use')parser.add_argument('--model', type=str, default='cnn', help='specify the model you use')args = parser.parse_args()# model caseif args.model == 'cnn':    batch_size = 4    model = CNN_mnist()    # model = CNN()    epochs = 30elif args.model == 'linear':    batch_size = 4    model = Linear_mnist()    epochs = 30# prepare train data and test datatransform = transforms.Compose(        [transforms.ToTensor(),            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])train_data = MNIST('~/Project/kronos/cnn/data/mnist_data/',        train=True, download=True,        transform=transform)train_loader = DataLoader(train_data, batch_size=batch_size,        shuffle=True)classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')criterion = nn.CrossEntropyLoss()optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)for epoch in range(epochs):    running_loss = 0.0    for i, data in enumerate(train_loader, 0):        inputs, labels = data        optimizer.zero_grad()        outputs = model(inputs)        loss = criterion(outputs, labels)        loss.backward()        optimizer.step()        running_loss += loss.item()        if i % (len(train_loader) / 10) == (len(train_loader) / 10 - 1):            print('[%d, %6d] loss: %.3f' %                    (epoch + 1, i + 1, running_loss / 2000))            running_loss = 0.0print('Finished Training!')if args.model == 'cnn':    torch.save(model.state_dict(), 'old_model_new_dataset.pth')elif args.model == 'linear':    torch.save(model.state_dict(), 'mnist_model_linear.pth')